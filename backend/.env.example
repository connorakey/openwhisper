# If you are not using Ollama, please leave the following two variables empty
OLLAMA_SERVER_URL=YOUR_OLLAMA_SERVER_URL_HERE
OLLAMA_SERVER_PORT=YOUR_PORT

# If you are not using LM studio, please leave the following two variables empty
LM_STUDIO_SERVER_URL=YOUR_LM_STUDIO_SERVER_URL_HERE
LM_STUDIO_SERVER_PORT=YOUR_PORT

# Change to either 'ollama', 'lm_studio', or 'cloud' depending on which LLM server you want to use
LLM_PROVIDER=YOUR_LLM_PROVIDER_HERE

# Change to the model name you want to use from your LLM server (ensure the model is already installed on the server)
LLM_MODEL_NAME=YOUR_LLM_MODEL_NAME_HERE

# Cloud API settings (only needed if using 'cloud' provider for LLM)
# Use OpenAI API or any OpenAI-compatible API (e.g., Together AI, OpenRouter, Azure OpenAI, etc.)
CLOUD_API_BASE_URL=https://api.openai.com/v1
CLOUD_API_KEY=YOUR_API_KEY_HERE

# Transcription API settings (only needed if using 'cloud' provider for transcription)
# Separate from LLM settings to allow different providers
TRANSCRIPTION_API_BASE_URL=https://audio-prod.api.fireworks.ai/v1
TRANSCRIPTION_API_KEY=YOUR_TRANSCRIPTION_API_KEY_HERE

# Transcription settings
# Change to either 'local' or 'cloud' - local uses Whisper models, cloud uses OpenAI-compatible API
TRANSCRIPTION_PROVIDER=local
# Model name to use for cloud transcription (whisper-v3 for Fireworks, whisper-large-v3 for Groq, whisper-1 for OpenAI)
TRANSCRIPTION_MODEL_NAME=whisper-v3
# Temperature for transcription (0-1, lower is more deterministic)
TRANSCRIPTION_TEMPERATURE=0
# VAD model for Fireworks AI (e.g., 'silero' for voice activity detection, leave empty for other providers)
TRANSCRIPTION_VAD_MODEL=silero

# Authorization header for API access
# To generate a new secure token, run: openssl rand -hex 32
API_AUTH_TOKEN=YOUR_AUTH_TOKEN_HERE
