# If you are not using Ollama, please leave the following two variables empty
OLLAMA_SERVER_URL=YOUR_OLLAMA_SERVER_URL_HERE
OLLAMA_SERVER_PORT=YOUR_PORT

# If you are not using LM studio, please leave the following two variables empty
LM_STUDIO_SERVER_URL=YOUR_LM_STUDIO_SERVER_URL_HERE
LM_STUDIO_SERVER_PORT=YOUR_PORT

# Change to either 'ollama', 'lm_studio', or 'cloud' depending on which LLM server you want to use
LLM_PROVIDER=YOUR_LLM_PROVIDER_HERE

# Change to the model name you want to use from your LLM server (ensure the model is already installed on the server)
LLM_MODEL_NAME=YOUR_LLM_MODEL_NAME_HERE

# Cloud API settings (only needed if using 'cloud' provider for LLM or transcription)
# Use OpenAI API or any OpenAI-compatible API (e.g., Together AI, OpenRouter, Azure OpenAI, etc.)
CLOUD_API_BASE_URL=https://api.openai.com/v1
CLOUD_API_KEY=YOUR_API_KEY_HERE

# Transcription settings
# Change to either 'local' or 'cloud' - local uses Whisper models, cloud uses OpenAI-compatible API
TRANSCRIPTION_PROVIDER=local
# Model name to use for cloud transcription (whisper-large-v3 is default, OpenAI uses whisper-1)
TRANSCRIPTION_MODEL_NAME=whisper-large-v3

# Authorization header for API access
# To generate a new secure token, run: openssl rand -hex 32
API_AUTH_TOKEN=YOUR_AUTH_TOKEN_HERE
